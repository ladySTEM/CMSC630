{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c66c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "CMSC 630 - Part 3\n",
    "Gabriella Graziani\n",
    "\n",
    "Execution File which processes cell images, performs segmentation, and \n",
    "outputs a csv file 'dataset.csv' containing extracted features from images\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "import os \n",
    "import time\n",
    "import json\n",
    "from scipy.signal import convolve2d\n",
    "import ImageProcessing\n",
    "import csv\n",
    "import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "983ab06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(input_file,sp_strength,gauss_noise_strength,gauss_noise_var,median_array,\n",
    "         lin_fil_w,lin_fil_h,lin_fil_sigma,img_height,img_width,r,erosion_iter,dilation_iter,k):\n",
    "\n",
    "    image_processing = ImageProcessing.ImageProcessing(img_height,img_width)\n",
    "    parent_dir = os.getcwd() #get current working directory\n",
    "    path = os.path.join(parent_dir,input_file) #add input file\n",
    "    all_images = os.listdir(path) #collect name of all images in file\n",
    "\n",
    "    #Create output files\n",
    "    file_list = ['Grayscale','Edges','Erosion','Dilation','GrayscaleSegmentation','ClusterSegmentation']#['Grayscale','SPNoise','GaussianNoise','Histograms',\n",
    "            #'EqualizedHistograms','LinearFilter','MedianFilter','AveragedHistograms','Edges','Erosion','Dilation','GrayscaleSegmentation','ClusteringSegmentation']\n",
    "    for item in file_list:\n",
    "        os.makedirs(item,exist_ok = True)\n",
    "\n",
    "\n",
    "   \n",
    "    feature_array = []\n",
    "\n",
    "    print(\"BEGINNING: Preprocessing and Feature Extraction\\n\")\n",
    "    st_batch = time.time()\n",
    "    img_tm = []\n",
    "    index = 0\n",
    "    for item in all_images:\n",
    "        st = time.time()\n",
    "        img_path = 'Cancerous cell smears/'+item\n",
    "        img = cv2.imread(img_path)\n",
    "        #img_path = 'EqualizedHistograms/'+item\n",
    "        print(\"Preprocessing {}, image {} of {} -- Percent complete: {}%\".format(item,index+1,len(all_images),((index+1)/len(all_images)*100)))\n",
    "        clustered_img = image_processing.clustering(img,2) \n",
    "        image_processing.save_img(clustered_img,\"ClusterSegmentation/\"+item)\n",
    "        \n",
    "        bw_img = image_processing.rgb2gray(clustered_img)\n",
    "        image_processing.save_img(bw_img,\"Grayscale/\"+item)\n",
    "        \n",
    "        back_img = image_processing.cluster_threshold(bw_img)\n",
    "        #image_processing.save_img(fore_img,\"GrayscaleSegmentation/foreground_\"+item)\n",
    "        image_processing.save_img(back_img,\"GrayscaleSegmentation/background_\"+item)\n",
    "        \n",
    "        edge_img = image_processing.find_edges(back_img)\n",
    "        image_processing.save_img(edge_img,\"Edges/\"+item)\n",
    "        \n",
    "        eros_img = image_processing.erosion(edge_img,r,erosion_iter)\n",
    "        image_processing.save_img(eros_img,\"Erosion/\"+item)\n",
    "        dila_img = image_processing.dilation(eros_img,r,dilation_iter)\n",
    "        image_processing.save_img(dila_img,\"Dilation/\"+item)\n",
    "        \n",
    "        fore_img = image_processing.extract_features(edge_img,back_img,img)\n",
    "        \n",
    "        fore_img.append(item[:-6])\n",
    "        \n",
    "        feature_array.append(fore_img)\n",
    "        index = index+1\n",
    "    \n",
    "        \n",
    "        et = time.time()\n",
    "        exec = et-st\n",
    "        img_tm.append(exec)\n",
    "    avg_tm = sum(img_tm)/len(img_tm)\n",
    "    et_batch = time.time()\n",
    "    bw_tm_batch = et_batch-st_batch\n",
    "    \n",
    "\n",
    "   # print(\"PreProcessing and Feature Extraction- Batch Execution time: {} Time per image: {}\\n\".format(bw_tm_batch,avg_tm))\n",
    "    \n",
    "    #print(feature_array)\n",
    "    labels = ['perimeter','area','mean_r','mean_g','mean_b','max_h_val','name']\n",
    "    with open('dataset4.csv','w',newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(labels)\n",
    "        for row in feature_array:\n",
    "            writer.writerow(row)\n",
    "            \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2075a14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGINNING: Preprocessing and Feature Extraction\n",
      "\n",
      "Preprocessing svar02.BMP, image 1 of 499 -- Percent complete: 0.2004008016032064%\n",
      "Preprocessing svar16.BMP, image 2 of 499 -- Percent complete: 0.4008016032064128%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.json\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 39\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(input_file, sp_strength, gauss_noise_strength, gauss_noise_var, median_array, lin_fil_w, lin_fil_h, lin_fil_sigma, img_height, img_width, r, erosion_iter, dilation_iter, k)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#image_processing.save_img(fore_img,\"GrayscaleSegmentation/foreground_\"+item)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m image_processing\u001b[38;5;241m.\u001b[39msave_img(back_img,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrayscaleSegmentation/background_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mitem)\n\u001b[0;32m---> 39\u001b[0m edge_img \u001b[38;5;241m=\u001b[39m \u001b[43mimage_processing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mback_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m image_processing\u001b[38;5;241m.\u001b[39msave_img(edge_img,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEdges/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mitem)\n\u001b[1;32m     42\u001b[0m eros_img \u001b[38;5;241m=\u001b[39m image_processing\u001b[38;5;241m.\u001b[39merosion(edge_img,r,erosion_iter)\n",
      "File \u001b[0;32m~/Documents/Image Analysis Project/ImageProcessing.py:242\u001b[0m, in \u001b[0;36mImageProcessing.find_edges\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(grad0\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(grad0\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m--> 242\u001b[0m         new_img[i,j] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(grad0[i,j]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39mgrad1[i,j]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39mgrad2[i,j]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39mgrad3[i,j]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39mgrad4[i,j]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39mgrad5[i,j]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39mgrad6[i,j]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39mgrad7[i,j]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    244\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[1;32m    245\u001b[0m edges \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(new_img)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    with open('config.json','r') as f:\n",
    "        config = json.load(f)\n",
    "    main(**config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
